---
title: 第一节 javaCV开始
date: 2022-02-09 10:38:03
tags: 流媒体
category: 死磕javaCV记录
top_img: https://s4.ax1x.com/2022/02/09/H8BFk8.jpg
cover: https://s4.ax1x.com/2022/02/09/H8BFk8.jpg
---
#### 前言
  javaCV是github上的一个项目，使用java做流媒体比较非主流，主流都是使用C/C++的库。但有总比没有强，虽然连个API都没有，
只能通过github只言片语的描述了解javaCV将ffmpeg、openCV等几十个库做了封装，使用javacpp方式为fmpeg、opencv等库
编译了各个系统环境的包方便跨平台调用。
#### 1、javaCV能做啥？
既然是"CV"，那自然是计算机视觉领域的库，比如音视频、图像处理、流媒体、深度学习、机器学习、人工智能等等，（deepleaming里有很多javaCV的库）。
通俗点讲就是用javaCV的库区采集音视频图像，然后给这个音视频图像编码，用什么格式封装，用什么协议传输，可能还要对视频里的图像处理（人脸识别啥的），
大致就这些。  
> **拉流（采集）-->图像像素数据/音频数据<-->编/解码<-->音/视频帧<-->解封装/封装-->推流**  
> 举例：编解码过程（以hevc编码的rtsp转rtmp/flv为例，⽆⾳频数据）  
> **rtsp流---拉流解复⽤--->h265(hevc)--解码-->yuv像素数据--编码-->h264--封装推流-->rtmp/flv**
#### 2、图像像素格式与图⽚封装格式
图像像素格式（简称像素格式），⼀般指的是没有经过编码的按照原始像素排列的数据。
举个栗⼦，⼀个完整图像的像素排列⼀般是这样的（以4*4像素的rgb像素格式为例）：  
> rgbrgbrgbrgb  
> rgbrgbrgbrgb    
> rgbrgbrgbrgb  
> rgbrgbrgbrgb
>
当然我们存储的时候⼀般使⽤⼀维数组来存这些数据，所以排列顺序就变成这样：rgbrgbrgbrgb.......以此类推。
图⽚封装格式指的我们⽇常⻅到的png，jpg，bmp，gif等等图⽚格式。其中bmp是⽆损格式且不压缩，⾥⾯的数据格式就
据；png是⽆损压缩格式；jpg/gif等都是有损压缩格式。压缩图⽚可以有效节省更多的硬盘空间。
#### 3、图像？视频帧？傻傻分不清楚
图像像素数据指的是yuv、rgb，rbga，bgr，gbra等图像像素格式，经过编码后才是视频帧。⽐如我们常⻅的h264编码，
缩，（以rgb为例，假如当前图像像素尺⼨为1920*1080，，每种颜⾊⽤⼀个字节表示，也就是说每个像素点有红绿蓝三
点，也就是说这张图像⼤⼩为1920*1080*3字节，显然数据太⼤了），可以这样理解，h264编码本质上就是⼀种图像数据
补充：视频帧中常常提到的I帧，B帧和P帧指的是什么？i帧也叫关键帧，实际上就是⼀张完整的静态图像，⽽B帧和P
⾮图像数据，B/P帧都需要依赖i帧才能够正确解码出完整图像（有损的图像画⾯）。在实际应⽤中各种视频源中很少
可以提⾼压缩率，但也会消耗更多的硬件性能，所以⼤多数情况下的视频源都以i帧（关键帧）和⼤量P帧为主。
另外在直播应⽤中i帧间隔会很低，这样能够更快的显示⾸帧画⾯（B/P帧需要i帧才能够解码），但是这样也增加了传
⼤。
#### 4、编码？封装？傻傻分不清楚
编码上⾯已经讲了，是⼀种压缩算法；那么封装格式⼜是什么呢，封装格式就是我们⽇常⻅到的视频⽂件了，⽐如mp4，
装格式的规范把视频帧和⾳频按照⼀定顺序存起来就成我们⽇常看到的视频⽂件了，这些封装格式⼀般都会包含⼀些头/尾
标识和一些视频描述信息。这样播放器读取视频⽂件的时候就知道该怎么播放这些视频⽂件了（可以把封装格式理解成收纳箱，
上⾯贴着⼩纸条说明⾥⾯放了哪些东西）。  
压缩图⽚格式也可以参考视频编码格式，原理都⼀样，都是对图像数据做有损/⽆损压缩。  
> 什么是转封装？为什么转封装⽐转码消耗更少？为什么转封装⽆法改动视频尺⼨？
先举个栗⼦：假设视频格式(mp4,flv,avi等)是盒⼦，⾥⾯的视频编码数据(h264,hevc)是苹果，我们把这个苹果从盒⼦⾥取出来放到另⼀个盒⼦⾥，盒⼦
是变了，苹果是没有变动的，因此视频相关的尺⼨数据是没有改动的，这个就是转封装的概念。
有了上⾯这个例⼦，我们可以把“转码”理解为：把这个盒⼦⾥的苹果(hevc)拿出来削⽪切块后再加⼯成樱桃(h264)后再装到另⼀个盒⼦⾥，多了⼀步对苹
果(hevc)转换为樱桃(h264)的操作，⾃然⽐直接把苹果拿到另⼀个盒⼦（转封装）要消耗更多机器性能。
#### 5、⾳/视频源
⾳/视频源可以是视频⽂件、⾳频⽂件，流媒体源，设备等等。
⽐如我们要看电脑或⼿机摄像头视频，就得采集设备的图像数据（从源设备采集到的是像素数据，⼀般是bgr或者rgb像素数据）如果是某些⼚商的商⽤摄像
机，可能会⽀持rtsp/rtmp协议，要采集声⾳呢，就得采集录⾳/话筒设备⾥⾯的数据（⼀般是pcm采样数据）。
#### 6、流媒体协议
rtsp协议栈，rtmp协议栈，hls，http-flv（理论上讲这个flv不能算是流媒体协议，它只是个⽆限⼤的flv⽂件）等等。
例如rtmp，对编码后的⾳视频帧，要对其进⾏封装成flv进⾏传输。
补充：说到底这些协议原理上依然是建⽴在tcp/udp基础上的应⽤层传输协议。
#### 7、流媒体服务
⽀持⾳视频存储分发的服务都可以叫流媒体服务。
⽐如常⻅的srs（开源的rtmp流媒体服务，当然它⽀持rtmp/hls/http-flv的分发）和nginx（通过安装模块可以⽀持rtmp，hls，http-flv分发），除此之外的收费的
和⼀些不太友好的开源流媒体服务就不⼀⼀介绍了。   
鉴于很多⼩伙伴还是⽐较混乱，为了⽅便理解，放⼀张总的⾳视频像素、编码、格式和协议及图⽚知识概念关系图：
![avatar](https://s4.ax1x.com/2022/02/09/HGCNHe.png)
流媒体协议层：rtsp、rtmp、hls
封装格式层：flv、ps、ts、图⽚格式（jpeg,png,gif）
⾳/视频编解码层：h264(AVC)、h265(HEVC)、h266(VVC)、AAC、PCMA
图像像素格式和⾳频采样层：YUV、RGB、RGBA等和PCM采样